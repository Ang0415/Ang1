# streamlit_app.py (Version 2: ê¸ˆí˜„ë¬¼ ê·¸ë˜í”„ ì¶”ê°€)

import streamlit as st
import pandas as pd
import numpy as np
import json
import os
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import traceback
import yfinance as yf
from collections.abc import Mapping # Secrets íƒ€ì… ì²´í¬ ìœ„í•´ ì¶”ê°€
import re # ìˆ«ì ì²˜ë¦¬ ìœ„í•´ ì¶”ê°€

# --- ê¸°ë³¸ ì„¤ì • ---
PAGE_TITLE = "í¬íŠ¸í´ë¦¬ì˜¤ ëŒ€ì‹œë³´ë“œ"
PAGE_ICON = "ğŸ“Š"
st.set_page_config(page_title=PAGE_TITLE, page_icon=PAGE_ICON, layout="wide")

# --- ê²½ë¡œ ì„¤ì • ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
TWR_CSV_PATH = os.path.join(CURRENT_DIR, 'twr_results.csv')
GAIN_LOSS_JSON_PATH = os.path.join(CURRENT_DIR, 'gain_loss.json')
GOOGLE_SHEET_NAME = 'KYI_ìì‚°ë°°ë¶„'
BALANCE_RAW_SHEET = 'ì¼ë³„ì”ê³ _Raw'
WEIGHTS_RAW_SHEET = 'ì¼ë³„ë¹„ì¤‘_Raw'
SETTINGS_SHEET = 'âš™ï¸ì„¤ì •'
TRADES_SHEET = 'ğŸ—“ï¸ë§¤ë§¤ì¼ì§€'
GOLD_RATE_SHEET = 'ğŸ“ˆê¸ˆí˜„ë¬¼ ìˆ˜ìµë¥ ' # ê¸ˆí˜„ë¬¼ ì‹œíŠ¸ ì´ë¦„ ì •ì˜

# --- ì§€ìˆ˜ í‹°ì»¤ ì„¤ì • ---
KOSPI_TICKER = "^KS200"
SP500_TICKER = "^GSPC"
# --- ---

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def clean_numeric_value(value, type_func=int):
    """ë‹¨ì¼ ê°’ì„ ìˆ«ìë¡œ ë³€í™˜ (ì‰¼í‘œ ë° íƒ€ì… ì²˜ë¦¬ ê°œì„ )"""
    if isinstance(value, (int, float)):
        # ì´ë¯¸ ìˆ«ì íƒ€ì…ì´ë©´ ì›í•˜ëŠ” íƒ€ì…ìœ¼ë¡œ ë³€í™˜ ì‹œë„
        try: return type_func(value)
        except (ValueError, TypeError): return type_func(0) # ë³€í™˜ ì‹¤íŒ¨ ì‹œ 0 ë°˜í™˜
    if not value: return type_func(0)
    try:
        # ìˆ«ì ë° ì†Œìˆ˜ì , ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ê´€ë ¨ ë¬¸ì ì™¸ ì œê±° (ì •ê·œì‹ ì‚¬ìš©)
        # (ì£¼ì˜: ê³¼í•™ì  í‘œê¸°ë²• 'e' ë“±ì€ ì²˜ë¦¬ ëª»í•¨)
        cleaned_str = re.sub(r'[^\d.-]+', '', str(value))
        if not cleaned_str or cleaned_str in ['-', '.']: return type_func(0)
        # floatìœ¼ë¡œ ë¨¼ì € ë³€í™˜ í›„ ìµœì¢… íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        num_val = float(cleaned_str)
        return type_func(num_val)
    except (ValueError, TypeError):
        return type_func(0)
# --- ---

# --- ë°ì´í„° ë¡œë”© í•¨ìˆ˜ë“¤ --- (ê¸°ì¡´ í•¨ìˆ˜ë“¤ì€ ë™ì¼)
@st.cache_data(ttl=600)
def load_twr_data():
    """TWR ê²°ê³¼ CSV íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        df = pd.read_csv(TWR_CSV_PATH, parse_dates=['Date'])
        print(f"Log: TWR ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({TWR_CSV_PATH})")
        return df
    except FileNotFoundError: st.warning(f"TWR ê²°ê³¼ íŒŒì¼({TWR_CSV_PATH})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `portfolio_performance.py`ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."); return pd.DataFrame()
    except Exception as e: st.error(f"TWR ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"); return pd.DataFrame()

@st.cache_data(ttl=600)
def load_gain_loss_data():
    """ë‹¨ìˆœ ì†ìµ ê²°ê³¼ JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(GAIN_LOSS_JSON_PATH, 'r', encoding='utf-8') as f: data = json.load(f)
        print(f"Log: ë‹¨ìˆœ ì†ìµ ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({GAIN_LOSS_JSON_PATH})")
        cleaned_data = {};
        for k, v in data.items(): cleaned_data[k] = None if isinstance(v, (int, float)) and (np.isnan(v) or np.isinf(v)) else v
        return cleaned_data
    except FileNotFoundError: st.warning(f"ë‹¨ìˆœ ì†ìµ ê²°ê³¼ íŒŒì¼({GAIN_LOSS_JSON_PATH})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `portfolio_performance.py`ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."); return {}
    except Exception as e: st.error(f"ë‹¨ìˆœ ì†ìµ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"); return {}

@st.cache_resource(ttl=600)
def connect_google_sheets():
    """êµ¬ê¸€ ì‹œíŠ¸ APIì— ì—°ê²°í•˜ê³  í´ë¼ì´ì–¸íŠ¸ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        if "gcs_credentials" not in st.secrets: st.error("Streamlit Secretsì— 'gcs_credentials'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤..."); return None
        creds_value = st.secrets["gcs_credentials"]; creds_dict = None
        if isinstance(creds_value, Mapping): print("Log: Reading secrets as dictionary-like object."); creds_dict = dict(creds_value)
        elif isinstance(creds_value, str):
            print("Log: Reading secrets as string, attempting JSON parse.")
            try: creds_dict = json.loads(creds_value)
            except json.JSONDecodeError:
                try: escaped_string = creds_value.replace("\n", "\\n"); creds_dict = json.loads(escaped_string); print("Log: JSON parsing successful after escaping newlines.")
                except json.JSONDecodeError as e_escaped: st.error(f"Secretsì˜ 'gcs_credentials' ê°’ JSON íŒŒì‹± ì˜¤ë¥˜: {e_escaped}..."); return None
        else: st.error(f"Secretsì˜ 'gcs_credentials' ê°’ íƒ€ì… ì˜¤ë¥˜..."); return None
        if creds_dict:
            creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope); gc = gspread.authorize(creds)
            gc.list_spreadsheet_files(); print("Log: Google Sheets ì—°ê²° ì„±ê³µ"); return gc
        else: st.error("ì¸ì¦ ì •ë³´(creds_dict)ë¥¼ ì¤€ë¹„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."); return None
    except KeyError as e: st.error(f"Streamlit Secrets ì ‘ê·¼ ì˜¤ë¥˜: í‚¤ '{e}' ì—†ìŒ..."); return None
    except Exception as e: st.error(f"êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨ (Secrets ì‚¬ìš© ì¤‘): {e}"); traceback.print_exc(); return None

@st.cache_data(ttl=600)
def load_latest_balances(_gc):
    """'ì¼ë³„ì”ê³ _Raw' ì‹œíŠ¸ì—ì„œ ê°€ì¥ ìµœê·¼ ë‚ ì§œì˜ ê³„ì¢Œë³„ ì´ìì‚°ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not isinstance(_gc, gspread.Client): st.error("load_latest_balances: ìœ íš¨í•œ Google Sheets í´ë¼ì´ì–¸íŠ¸ ê°ì²´(gc)ê°€ ì•„ë‹™ë‹ˆë‹¤."); return {}, None
    try:
        spreadsheet = _gc.open(GOOGLE_SHEET_NAME); worksheet = spreadsheet.worksheet(BALANCE_RAW_SHEET)
        data = worksheet.get_all_records(); latest_date = None # ì´ˆê¸°í™”
        if not data: st.warning(f"'{BALANCE_RAW_SHEET}' ì‹œíŠ¸ ë°ì´í„° ì—†ìŒ."); return {}, None
        df = pd.DataFrame(data); df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], errors='coerce')
        valid_dates = df.dropna(subset=['ë‚ ì§œ'])
        if valid_dates.empty: st.warning(f"'{BALANCE_RAW_SHEET}' ìœ íš¨ ë‚ ì§œ ë°ì´í„° ì—†ìŒ."); return {}, None
        latest_date = valid_dates['ë‚ ì§œ'].max() # ë‚ ì§œ ê³„ì‚° í›„ í• ë‹¹
        latest_df = df[df['ë‚ ì§œ'] == latest_date].copy()
        if 'ì´ìì‚°' not in latest_df.columns: st.error(f"'{BALANCE_RAW_SHEET}' ì‹œíŠ¸ì— 'ì´ìì‚°' ì»¬ëŸ¼ ì—†ìŒ."); return {}, latest_date
        latest_df['ì´ìì‚°_num'] = pd.to_numeric(latest_df['ì´ìì‚°'].astype(str).str.replace(',','', regex=False), errors='coerce')
        balances = latest_df.dropna(subset=['ì´ìì‚°_num']).set_index('ê³„ì¢Œëª…')['ì´ìì‚°_num'].to_dict()
        print(f"Log: ìµœì‹  ì”ê³  ë°ì´í„° ë¡œë“œ ì™„ë£Œ (ë‚ ì§œ: {latest_date.strftime('%Y-%m-%d')})")
        return balances, latest_date
    except gspread.exceptions.WorksheetNotFound: st.error(f"ì›Œí¬ì‹œíŠ¸ '{BALANCE_RAW_SHEET}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ."); return {}, None
    except Exception as e: st.error(f"'ì¼ë³„ì”ê³ _Raw' ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}"); traceback.print_exc(); return {}, None

@st.cache_data(ttl=600)
def load_allocation_data(_gc, latest_data_date):
    """ìì‚° ë°°ë¶„ ë°ì´í„°('âš™ï¸ì„¤ì •', 'ì¼ë³„ë¹„ì¤‘_Raw')ë¥¼ ë¡œë“œí•˜ê³  ë¹„êµ í…Œì´ë¸” ìƒì„±"""
    # (ì´ì „ ë²„ì „ê³¼ ë™ì¼)
    if not isinstance(_gc, gspread.Client) or not isinstance(latest_data_date, pd.Timestamp): st.error("load_allocation_data: ìœ íš¨í•œ gc ë˜ëŠ” latest_data_date ì•„ë‹˜."); return pd.DataFrame(), pd.DataFrame()
    settings_df = pd.DataFrame(); target_allocation_map = {}; comparison_df_final = pd.DataFrame(); current_weights_df = pd.DataFrame()
    BASE_TOTAL_ASSET = 80000000
    try:
        spreadsheet = _gc.open(GOOGLE_SHEET_NAME); settings_ws = spreadsheet.worksheet(SETTINGS_SHEET); settings_values = settings_ws.get_all_values()
        if len(settings_values) > 1:
            header = settings_values[0]
            try:
                required_cols = ['ëª©í‘œêµ¬ë¶„', 'ëª©í‘œêµ­ì ', 'ëª©í‘œë¹„ì¤‘']; col_indices = {}; missing_cols = []
                for col in required_cols:
                    try: col_indices[col] = header.index(col)
                    except ValueError: missing_cols.append(col)
                if missing_cols: raise ValueError(f"ì„¤ì • ì‹œíŠ¸ í—¤ë” ì˜¤ë¥˜: {missing_cols} ëˆ„ë½")
                target_class_col, target_nation_col, target_perc_col = col_indices['ëª©í‘œêµ¬ë¶„'], col_indices['ëª©í‘œêµ­ì '], col_indices['ëª©í‘œë¹„ì¤‘']
                processed_targets_combined = {}; unique_target_keys = set()
                for i, row in enumerate(settings_values[1:]):
                    if len(row) > max(target_class_col, target_nation_col, target_perc_col):
                        try:
                            asset_class = str(row[target_class_col]).strip(); nationality = str(row[target_nation_col]).strip(); target_perc_str = str(row[target_perc_col]).strip().replace('%','')
                            combined_key = (asset_class, nationality)
                            if asset_class and nationality and target_perc_str:
                                if combined_key not in unique_target_keys:
                                     try:
                                         target_perc = float(target_perc_str)
                                         if target_perc > 0:
                                             combined_name = f"{nationality} {asset_class}" if asset_class != 'ëŒ€ì²´íˆ¬ì' else "ê¸ˆ"
                                             processed_targets_combined[combined_name] = target_perc; unique_target_keys.add(combined_key)
                                     except ValueError: pass
                        except Exception as e_row: print(f"Log: ì„¤ì • {i+2}í–‰ ëª©í‘œ ì²˜ë¦¬ ì˜¤ë¥˜: {e_row}")
                target_allocation_map = processed_targets_combined
                if target_allocation_map: target_df = pd.DataFrame(list(target_allocation_map.items()), columns=['ì¢…í•© ë¶„ë¥˜', 'ëª©í‘œ ë¹„ì¤‘(%)']); settings_df = target_df[target_df['ëª©í‘œ ë¹„ì¤‘(%)'] > 0].sort_values(by='ëª©í‘œ ë¹„ì¤‘(%)', ascending=False); print(f"Log: ëª©í‘œ ë¹„ì¤‘ ë¡œë“œ ì™„ë£Œ: {len(settings_df)}ê°œ í•­ëª©")
                else: print("Log: ëª©í‘œ ë¹„ì¤‘ ì •ë³´ ì—†ìŒ.")
            except ValueError as e_col: st.error(f"ì„¤ì • ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘ ê°’ ì˜¤ë¥˜: {e_col}"); traceback.print_exc()
            except Exception as e_set: st.error(f"ì„¤ì • ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e_set}"); traceback.print_exc()
        else: print("Log: ì„¤ì • ì‹œíŠ¸ ë°ì´í„° ì—†ìŒ.")

        weights_ws = spreadsheet.worksheet(WEIGHTS_RAW_SHEET); weights_data = weights_ws.get_all_records()
        if not weights_data:
            st.warning("'ì¼ë³„ë¹„ì¤‘_Raw' ì‹œíŠ¸ ë°ì´í„° ì—†ìŒ."); comparison_df_final = pd.DataFrame(columns=['ì¢…í•© ë¶„ë¥˜', 'í˜„ì¬ ë¹„ì¤‘(%)', 'í˜„ì¬ í‰ê°€ì•¡', 'ëª©í‘œ ë¹„ì¤‘(%)', 'ëª©í‘œ ê¸ˆì•¡', 'ì°¨ì´(%)', 'í˜„ê¸ˆì°¨ì´'])
            if not settings_df.empty: comparison_df_final = settings_df.rename(columns={'ëª©í‘œ ë¹„ì¤‘(%)':'ëª©í‘œ ë¹„ì¤‘(%)'}); comparison_df_final['í˜„ì¬ ë¹„ì¤‘(%)'] = 0.0; comparison_df_final['í˜„ì¬ í‰ê°€ì•¡'] = 0; comparison_df_final['ëª©í‘œ ê¸ˆì•¡'] = (BASE_TOTAL_ASSET * (comparison_df_final['ëª©í‘œ ë¹„ì¤‘(%)'] / 100)).round(0).astype(int); comparison_df_final['ì°¨ì´(%)'] = -comparison_df_final['ëª©í‘œ ë¹„ì¤‘(%)']; comparison_df_final['í˜„ê¸ˆì°¨ì´'] = -comparison_df_final['ëª©í‘œ ê¸ˆì•¡']
            return comparison_df_final.round({'ì°¨ì´(%)': 2}), settings_df

        weights_df = pd.DataFrame(weights_data); weights_df['ë‚ ì§œ'] = pd.to_datetime(weights_df['ë‚ ì§œ'], errors='coerce')
        latest_weights_df = weights_df[weights_df['ë‚ ì§œ'] == latest_data_date].copy()
        if latest_weights_df.empty:
             st.warning(f"{latest_data_date.strftime('%Y-%m-%d')} ë‚ ì§œì˜ ë¹„ì¤‘ ë°ì´í„° ì—†ìŒ."); comparison_df_final = pd.DataFrame(columns=['ì¢…í•© ë¶„ë¥˜', 'í˜„ì¬ ë¹„ì¤‘(%)', 'í˜„ì¬ í‰ê°€ì•¡', 'ëª©í‘œ ë¹„ì¤‘(%)', 'ëª©í‘œ ê¸ˆì•¡', 'ì°¨ì´(%)', 'í˜„ê¸ˆì°¨ì´'])
             if not settings_df.empty: comparison_df_final = settings_df.rename(columns={'ëª©í‘œ ë¹„ì¤‘(%)':'ëª©í‘œ ë¹„ì¤‘(%)'}); comparison_df_final['í˜„ì¬ ë¹„ì¤‘(%)'] = 0.0; comparison_df_final['í˜„ì¬ í‰ê°€ì•¡'] = 0; comparison_df_final['ëª©í‘œ ê¸ˆì•¡'] = (BASE_TOTAL_ASSET * (comparison_df_final['ëª©í‘œ ë¹„ì¤‘(%)'] / 100)).round(0).astype(int); comparison_df_final['ì°¨ì´(%)'] = -comparison_df_final['ëª©í‘œ ë¹„ì¤‘(%)']; comparison_df_final['í˜„ê¸ˆì°¨ì´'] = -comparison_df_final['ëª©í‘œ ê¸ˆì•¡']
             return comparison_df_final.round({'ì°¨ì´(%)': 2}), settings_df

        required_weight_cols = ['ìì‚°êµ¬ë¶„', 'í¬íŠ¸í´ë¦¬ì˜¤ë‚´ë¹„ì¤‘(%)', 'í‰ê°€ê¸ˆì•¡']; missing_weight_cols = [col for col in required_weight_cols if col not in latest_weights_df.columns]; has_nationality_col = 'êµ­ì ' in latest_weights_df.columns
        if not has_nationality_col: st.warning("'ì¼ë³„ë¹„ì¤‘_Raw' ì‹œíŠ¸ì— 'êµ­ì ' ì»¬ëŸ¼ ì—†ìŒ.")
        if missing_weight_cols: st.error(f"'{WEIGHTS_RAW_SHEET}' ì‹œíŠ¸ì— í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_weight_cols}"); return pd.DataFrame(), settings_df

        def get_combined_name(row):
            asset_class = str(row.get('ìì‚°êµ¬ë¶„', '')).strip(); nationality = str(row.get('êµ­ì ', '')).strip() if has_nationality_col else ""
            if not asset_class: return 'ë¯¸ë¶„ë¥˜'
            if asset_class == 'ëŒ€ì²´íˆ¬ì': return "ê¸ˆ"
            elif not nationality: return asset_class
            else: return f"{nationality} {asset_class}"

        latest_weights_df['ì¢…í•© ë¶„ë¥˜'] = latest_weights_df.apply(get_combined_name, axis=1)
        latest_weights_df['í˜„ì¬ ë¹„ì¤‘(%)'] = pd.to_numeric(latest_weights_df['í¬íŠ¸í´ë¦¬ì˜¤ë‚´ë¹„ì¤‘(%)'], errors='coerce').fillna(0.0)
        latest_weights_df['í˜„ì¬ í‰ê°€ì•¡'] = pd.to_numeric(latest_weights_df['í‰ê°€ê¸ˆì•¡'].astype(str).str.replace(',','', regex=False), errors='coerce').fillna(0).astype(int)
        current_weights_grouped = latest_weights_df.groupby('ì¢…í•© ë¶„ë¥˜').agg({'í˜„ì¬ ë¹„ì¤‘(%)': 'sum', 'í˜„ì¬ í‰ê°€ì•¡': 'sum'}).reset_index()
        current_weights_df = current_weights_grouped[current_weights_grouped['í˜„ì¬ ë¹„ì¤‘(%)'] > 0].sort_values(by='í˜„ì¬ ë¹„ì¤‘(%)', ascending=False)
        print(f"Log: í˜„ì¬ ë¹„ì¤‘ ë° í‰ê°€ì•¡ ê³„ì‚° ì™„ë£Œ: {len(current_weights_df)}ê°œ í•­ëª©")

        if not current_weights_df.empty:
            if not settings_df.empty: comparison_df = current_weights_df.merge(settings_df.set_index('ì¢…í•© ë¶„ë¥˜'), on='ì¢…í•© ë¶„ë¥˜', how='outer').fillna(0)
            else: comparison_df = current_weights_df.copy(); comparison_df['ëª©í‘œ ë¹„ì¤‘(%)'] = 0.0
            for col in ['í˜„ì¬ ë¹„ì¤‘(%)', 'í˜„ì¬ í‰ê°€ì•¡', 'ëª©í‘œ ë¹„ì¤‘(%)']:
                if col not in comparison_df.columns: comparison_df[col] = 0.0 if '%' in col else 0
            comparison_df['ì°¨ì´(%)'] = comparison_df['í˜„ì¬ ë¹„ì¤‘(%)'] - comparison_df['ëª©í‘œ ë¹„ì¤‘(%)']
            comparison_df['ëª©í‘œ ê¸ˆì•¡'] = BASE_TOTAL_ASSET * (comparison_df['ëª©í‘œ ë¹„ì¤‘(%)'] / 100)
            comparison_df['í˜„ê¸ˆì°¨ì´'] = comparison_df['í˜„ì¬ í‰ê°€ì•¡'] - comparison_df['ëª©í‘œ ê¸ˆì•¡']
            for col in ['í˜„ì¬ í‰ê°€ì•¡', 'ëª©í‘œ ê¸ˆì•¡', 'í˜„ê¸ˆì°¨ì´']:
                 if col in comparison_df.columns: comparison_df[col] = comparison_df[col].round(0).astype(int)
            comparison_df_final = comparison_df
            print("Log: í˜„ì¬/ëª©í‘œ ë¹„ì¤‘ ë° ê¸ˆì•¡ ë¹„êµ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
        else:
             print("Log: í˜„ì¬ ë¹„ì¤‘ ì •ë³´ ì—†ìŒ.")
             if not settings_df.empty: comparison_df_final = settings_df.rename(columns={'ëª©í‘œ ë¹„ì¤‘(%)':'ëª©í‘œ ë¹„ì¤‘(%)'}); comparison_df_final['í˜„ì¬ ë¹„ì¤‘(%)'] = 0.0; comparison_df_final['í˜„ì¬ í‰ê°€ì•¡'] = 0; comparison_df_final['ëª©í‘œ ê¸ˆì•¡'] = (BASE_TOTAL_ASSET * (comparison_df_final['ëª©í‘œ ë¹„ì¤‘(%)'] / 100)).round(0).astype(int); comparison_df_final['ì°¨ì´(%)'] = -comparison_df_final['ëª©í‘œ ë¹„ì¤‘(%)']; comparison_df_final['í˜„ê¸ˆì°¨ì´'] = -comparison_df_final['ëª©í‘œ ê¸ˆì•¡']
             else: comparison_df_final = pd.DataFrame(columns=['ì¢…í•© ë¶„ë¥˜', 'í˜„ì¬ ë¹„ì¤‘(%)', 'í˜„ì¬ í‰ê°€ì•¡', 'ëª©í‘œ ë¹„ì¤‘(%)', 'ëª©í‘œ ê¸ˆì•¡', 'ì°¨ì´(%)', 'í˜„ê¸ˆì°¨ì´'])

    except gspread.exceptions.WorksheetNotFound as e_ws: st.error(f"ì›Œí¬ì‹œíŠ¸ '{e_ws.args[0] if e_ws.args else ''}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ.")
    except Exception as e: st.error(f"ìì‚° ë°°ë¶„ ë°ì´í„° ë¡œë”©/ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}"); traceback.print_exc()

    final_cols_order = ['ì¢…í•© ë¶„ë¥˜', 'í˜„ì¬ ë¹„ì¤‘(%)', 'í˜„ì¬ í‰ê°€ì•¡', 'ëª©í‘œ ë¹„ì¤‘(%)', 'ëª©í‘œ ê¸ˆì•¡', 'ì°¨ì´(%)', 'í˜„ê¸ˆì°¨ì´']
    available_final_cols = [col for col in final_cols_order if col in comparison_df_final.columns]
    return comparison_df_final[available_final_cols], settings_df

@st.cache_data(ttl=3600)
def download_yf_data(ticker, start_date, end_date):
    """Yahoo Finance ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ê¸°ì¡´ê³¼ ë™ì¼)"""
    try:
        end_date_adj = pd.to_datetime(end_date) + timedelta(days=1)
        data = yf.download(ticker, start=start_date, end=end_date_adj, progress=False, auto_adjust=True) # auto_adjust=True ì¶”ê°€
        if data.empty: st.warning(f"âš ï¸ {ticker} ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨."); return pd.DataFrame()
        if isinstance(data.index, pd.DatetimeIndex): data.index = data.index.tz_localize(None) # ì‹œê°„ëŒ€ ì •ë³´ ì œê±°
        return data
    except Exception as e: st.error(f"{ticker} ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}"); return pd.DataFrame()

@st.cache_data
def calculate_index_twr(index_df, ticker):
    """ì£¼ê°€ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ TWR(%) ê³„ì‚° (ê¸°ì¡´ê³¼ ë™ì¼, ì…ë ¥ DataFrame ì²˜ë¦¬ ê°•í™”)"""
    if index_df is None or index_df.empty or len(index_df) < 2: return pd.DataFrame()
    # 'Close' ì»¬ëŸ¼ ì°¾ê¸° (MultiIndex ë˜ëŠ” ì¼ë°˜ Index ê³ ë ¤)
    close_col_name = None
    if isinstance(index_df.columns, pd.MultiIndex):
        # yfinanceê°€ ê°€ë” ('Adj Close', '') ê°™ì€ ì‹ìœ¼ë¡œ ë°˜í™˜í•  ë•Œ ëŒ€ë¹„
        potential_cols = [('Close', ticker), ('Adj Close', ticker), ('Close', ''), ('Adj Close', '')]
        for col in potential_cols:
            if col in index_df.columns: close_col_name = col; break
        if not close_col_name: # ê·¸ë˜ë„ ëª» ì°¾ìœ¼ë©´ 'Close'ë‚˜ 'Adj Close' ë ˆë²¨ì—ì„œ ì°¾ê¸°
             level_zero = index_df.columns.get_level_values(0)
             if 'Close' in level_zero: close_col_name = [c for c in index_df.columns if c[0] == 'Close'][0]
             elif 'Adj Close' in level_zero: close_col_name = [c for c in index_df.columns if c[0] == 'Adj Close'][0]
    elif 'Close' in index_df.columns: close_col_name = 'Close'
    elif 'Adj Close' in index_df.columns: close_col_name = 'Adj Close'

    if close_col_name is None: st.warning(f"{ticker} TWR ê³„ì‚° ë¶ˆê°€: ì¢…ê°€('Close') ì»¬ëŸ¼ ëª» ì°¾ìŒ."); return pd.DataFrame()

    df = index_df[[close_col_name]].copy(); df.columns = ['Close'] # ì»¬ëŸ¼ ì´ë¦„ í†µì¼
    df = df.dropna().astype('float64')
    if not pd.api.types.is_float_dtype(df['Close']) or df.empty: return pd.DataFrame()

    df = df.sort_index(); df['StartValue'] = df['Close'].shift(1); df = df.iloc[1:].copy()
    if df.empty: return pd.DataFrame()
    denominator = df['StartValue']
    df['DailyFactor'] = 1.0
    valid_calc_mask = (denominator.abs() > 1e-9) # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒ ë°©ì§€
    df.loc[valid_calc_mask, 'DailyFactor'] = (df.loc[valid_calc_mask, 'Close'] / denominator.loc[valid_calc_mask])
    df['DailyFactor'] = df['DailyFactor'].replace([np.inf, -np.inf], np.nan).fillna(1.0)
    df['DailyFactor'] = df['DailyFactor'].clip(lower=0.1, upper=10.0) # ì´ìƒì¹˜ ì œí•œ
    df['CumulativeFactor'] = df['DailyFactor'].cumprod()
    df['TWR'] = (df['CumulativeFactor'] - 1.0) * 100.0
    return df[['TWR']].reset_index()

@st.cache_data(ttl=600)
def load_current_holdings(_gc, latest_data_date):
    """'ì¼ë³„ë¹„ì¤‘_Raw' ì‹œíŠ¸ì—ì„œ í˜„ì¬ ë³´ìœ  ì¢…ëª© ëª©ë¡ ë¡œë“œ (ê¸°ì¡´ê³¼ ë™ì¼)"""
    if not isinstance(_gc, gspread.Client) or not isinstance(latest_data_date, pd.Timestamp): st.error("load_current_holdings: ìœ íš¨í•œ gc ë˜ëŠ” latest_data_date ì•„ë‹˜."); return pd.DataFrame(columns=['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…'])
    try:
        spreadsheet = _gc.open(GOOGLE_SHEET_NAME); weights_ws = spreadsheet.worksheet(WEIGHTS_RAW_SHEET)
        weights_data = weights_ws.get_all_records(); holdings_df = pd.DataFrame(columns=['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…']) # ê¸°ë³¸ê°’
        if not weights_data: st.warning(f"'{WEIGHTS_RAW_SHEET}' ì‹œíŠ¸ ë°ì´í„° ì—†ìŒ."); return holdings_df
        weights_df = pd.DataFrame(weights_data); weights_df['ë‚ ì§œ'] = pd.to_datetime(weights_df['ë‚ ì§œ'], errors='coerce')
        latest_weights_df = weights_df[weights_df['ë‚ ì§œ'] == latest_data_date].copy()
        if latest_weights_df.empty: st.warning(f"{latest_data_date.strftime('%Y-%m-%d')} ë‚ ì§œì˜ ë¹„ì¤‘ ë°ì´í„° ì—†ìŒ."); return holdings_df
        required_cols = ['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…', 'í‰ê°€ê¸ˆì•¡']; missing_cols = [col for col in required_cols if col not in latest_weights_df.columns]
        if missing_cols: st.error(f"'{WEIGHTS_RAW_SHEET}' í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}."); return holdings_df
        latest_weights_df['í‰ê°€ê¸ˆì•¡_num'] = pd.to_numeric(latest_weights_df['í‰ê°€ê¸ˆì•¡'].astype(str).str.replace(',','', regex=False), errors='coerce').fillna(0).astype(int)
        latest_weights_df['ì¢…ëª©ëª…_ì •ë¦¬'] = latest_weights_df['ì¢…ëª©ëª…'].astype(str).str.replace(' ', '')
        holdings_df = latest_weights_df[latest_weights_df['í‰ê°€ê¸ˆì•¡_num'] > 0][['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…_ì •ë¦¬']].rename(columns={'ì¢…ëª©ëª…_ì •ë¦¬':'ì¢…ëª©ëª…'}).drop_duplicates().sort_values(by='ì¢…ëª©ëª…').reset_index(drop=True)
        gold_mask = (holdings_df['ì¢…ëª©ëª…'] == 'ê¸ˆí˜„ë¬¼') | (holdings_df['ì¢…ëª©ëª…'] == 'ê¸ˆ'); code_missing_mask = holdings_df['ì¢…ëª©ì½”ë“œ'].isnull() | (holdings_df['ì¢…ëª©ì½”ë“œ'].astype(str).str.strip() == ''); rows_to_update = gold_mask & code_missing_mask
        if rows_to_update.any(): holdings_df.loc[rows_to_update, 'ì¢…ëª©ì½”ë“œ'] = 'GOLD'; print(f"Log: '{holdings_df.loc[rows_to_update, 'ì¢…ëª©ëª…'].iloc[0]}' í•­ëª©ì— 'GOLD' ì½”ë“œ í• ë‹¹ë¨.")
        print(f"Log: í˜„ì¬ ë³´ìœ  ì¢…ëª© ëª©ë¡ ë¡œë“œ ì™„ë£Œ ({len(holdings_df)} ì¢…ëª©)")
        return holdings_df
    except gspread.exceptions.WorksheetNotFound: st.error(f"ì›Œí¬ì‹œíŠ¸ '{WEIGHTS_RAW_SHEET}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ."); return pd.DataFrame(columns=['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…'])
    except Exception as e: st.error(f"ë³´ìœ  ì¢…ëª© ëª©ë¡ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}"); traceback.print_exc(); return pd.DataFrame(columns=['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…'])

@st.cache_data(ttl=300)
def calculate_moving_avg_cost(_gc, stock_code):
    """'ğŸ—“ï¸ë§¤ë§¤ì¼ì§€' ì‹œíŠ¸ì—ì„œ ì´ë™í‰ê· ë²•ìœ¼ë¡œ í‰ë‹¨ê°€ ê³„ì‚° (ê¸°ì¡´ê³¼ ë™ì¼, ìˆ«ì ë³€í™˜ í•¨ìˆ˜ ì‚¬ìš©)"""
    if not isinstance(_gc, gspread.Client): st.error("calculate_moving_avg_cost: ìœ íš¨í•œ Google Sheets í´ë¼ì´ì–¸íŠ¸ ê°ì²´(gc)ê°€ ì•„ë‹™ë‹ˆë‹¤."); return 0.0
    if not stock_code: return 0.0
    final_avg_cost = 0.0
    TRADE_DATE_HEADER = 'ë‚ ì§œ'; TRADE_TYPE_HEADER = 'ë§¤ë§¤êµ¬ë¶„'; TRADE_PRICE_HEADER = 'ë‹¨ê°€'; TRADE_QTY_HEADER = 'ìˆ˜ëŸ‰'; TRADE_CODE_HEADER = 'ì¢…ëª©ì½”ë“œ'
    try:
        spreadsheet = _gc.open(GOOGLE_SHEET_NAME); trades_ws = spreadsheet.worksheet(TRADES_SHEET)
        all_trades_records = trades_ws.get_all_records()
        if not all_trades_records: return final_avg_cost
        trades_df = pd.DataFrame(all_trades_records)
        required_trade_headers = [TRADE_DATE_HEADER, TRADE_TYPE_HEADER, TRADE_PRICE_HEADER, TRADE_QTY_HEADER, TRADE_CODE_HEADER]
        missing_trade_headers = [h for h in required_trade_headers if h not in trades_df.columns]
        if missing_trade_headers: st.error(f"'{TRADES_SHEET}' í•„ìˆ˜ í—¤ë” ëˆ„ë½: {missing_trade_headers}"); return final_avg_cost
        trades_df['Date'] = pd.to_datetime(trades_df[TRADE_DATE_HEADER], errors='coerce')
        trades_df = trades_df.dropna(subset=['Date']).sort_values(by='Date')
        stock_code_str = str(stock_code).strip().upper().replace('KRX:', '').replace('A','')
        is_gold = (stock_code_str == 'GOLD')
        def code_match(row_code):
            row_code_str = str(row_code).strip().upper().replace('KRX:', '').replace('A','')
            if is_gold: return row_code_str == 'GOLD'
            else: return row_code_str == stock_code_str
        filtered_trades_df = trades_df[trades_df[TRADE_CODE_HEADER].apply(code_match)]
        if filtered_trades_df.empty: return final_avg_cost
        current_qty = 0.0; total_cost = 0.0 # ìˆ˜ëŸ‰, ë¹„ìš© floatìœ¼ë¡œ ì²˜ë¦¬
        for index, row in filtered_trades_df.iterrows():
            row_type = str(row[TRADE_TYPE_HEADER]).strip()
            try:
                # clean_numeric_value ì‚¬ìš©í•˜ì—¬ ìˆ«ì ë³€í™˜
                qty = clean_numeric_value(row[TRADE_QTY_HEADER], float) # floatìœ¼ë¡œ ìˆ˜ëŸ‰ ì²˜ë¦¬
                price = clean_numeric_value(row[TRADE_PRICE_HEADER], float)
                if row_type == 'ë§¤ìˆ˜':
                    if qty > 0 and price >= 0: cost_of_buy = qty * price; total_cost += cost_of_buy; current_qty += qty
                elif row_type == 'ë§¤ë„':
                    if qty > 0 and current_qty > 1e-9: # 0ì— ê°€ê¹Œìš´ì§€ ë¹„êµ
                        sell_qty = min(qty, current_qty); avg_cost_before_sell = total_cost / current_qty
                        cost_of_sold = sell_qty * avg_cost_before_sell; total_cost -= cost_of_sold; current_qty -= sell_qty
                        if abs(current_qty) < 1e-9: total_cost = 0.0 # 0ì— ê°€ê¹Œìš°ë©´ ë¹„ìš© ì´ˆê¸°í™”
            except Exception as e_row: print(f"Log: Row {index} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ì´ë™í‰ê· ): {e_row}"); continue
        if current_qty > 1e-9: final_avg_cost = total_cost / current_qty
        else: final_avg_cost = 0.0
        print(f"Log: {stock_code} ìµœì¢… í‰ë‹¨ê°€(ì´ë™í‰ê· ): {final_avg_cost:.2f}")
    except gspread.exceptions.WorksheetNotFound: st.error(f"ì›Œí¬ì‹œíŠ¸ '{TRADES_SHEET}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ.")
    except KeyError as e: st.error(f"'{TRADES_SHEET}' ì‹œíŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: ì»¬ëŸ¼ '{e}' í™•ì¸ í•„ìš”.")
    except Exception as e: st.error(f"í‰ë‹¨ê°€(ì´ë™í‰ê· ) ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}"); traceback.print_exc()
    # ê¸ˆ ê°€ê²©ì€ ì†Œìˆ˜ì  í•„ìš”í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ float ë°˜í™˜
    return float(final_avg_cost)

@st.cache_data(ttl=3600)
def get_first_purchase_date(_gc, stock_code):
    """'ğŸ—“ï¸ë§¤ë§¤ì¼ì§€' ì‹œíŠ¸ì—ì„œ ìµœì´ˆ ë§¤ìˆ˜ì¼ ì°¾ê¸° (ê¸°ì¡´ê³¼ ë™ì¼)"""
    if not isinstance(_gc, gspread.Client): st.error("get_first_purchase_date: ìœ íš¨í•œ Google Sheets í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ì•„ë‹˜."); return None
    if not stock_code: return None
    first_date = None
    TRADE_DATE_HEADER = 'ë‚ ì§œ'; TRADE_TYPE_HEADER = 'ë§¤ë§¤êµ¬ë¶„'; TRADE_CODE_HEADER = 'ì¢…ëª©ì½”ë“œ'
    try:
        spreadsheet = _gc.open(GOOGLE_SHEET_NAME); trades_ws = spreadsheet.worksheet(TRADES_SHEET)
        all_trades_records = trades_ws.get_all_records()
        if not all_trades_records: return None
        trades_df = pd.DataFrame(all_trades_records)
        required_trade_headers = [TRADE_DATE_HEADER, TRADE_TYPE_HEADER, TRADE_CODE_HEADER]
        missing_trade_headers = [h for h in required_trade_headers if h not in trades_df.columns]
        if missing_trade_headers: st.error(f"'{TRADES_SHEET}' í•„ìˆ˜ í—¤ë” ëˆ„ë½: {missing_trade_headers}"); return None
        trades_df['Date'] = pd.to_datetime(trades_df[TRADE_DATE_HEADER], errors='coerce')
        trades_df = trades_df.dropna(subset=['Date'])
        stock_code_str = str(stock_code).strip().upper().replace('KRX:', '').replace('A','')
        is_gold = (stock_code_str == 'GOLD')
        def code_match(row_code):
            row_code_str = str(row_code).strip().upper().replace('KRX:', '').replace('A','')
            if is_gold: return row_code_str == 'GOLD'
            else: return row_code_str == stock_code_str
        purchase_trades_df = trades_df[(trades_df[TRADE_CODE_HEADER].apply(code_match)) & (trades_df[TRADE_TYPE_HEADER] == 'ë§¤ìˆ˜')]
        if not purchase_trades_df.empty: first_date = purchase_trades_df['Date'].min(); print(f"Log: Success! First purchase date for '{stock_code}': {first_date.strftime('%Y-%m-%d')}")
        else: print(f"Log: Failed to find valid purchase date for '{stock_code}'.")
    except gspread.exceptions.WorksheetNotFound: st.error(f"ì›Œí¬ì‹œíŠ¸ '{TRADES_SHEET}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ.")
    except Exception as e: st.error(f"ìµœì´ˆ ë§¤ìˆ˜ì¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}"); traceback.print_exc()
    return first_date

def get_yf_ticker(stock_code):
    """ì¢…ëª©ì½”ë“œë¥¼ Yahoo Finance í‹°ì»¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ê¸°ì¡´ê³¼ ë™ì¼)"""
    code = str(stock_code).strip()
    if code == 'GOLD': return None
    if code.startswith('KRX:'): code_only = code.split(':')[-1]
    elif code.startswith('A') and code[1:].isdigit(): code_only = code[1:]
    else: code_only = code
    if code_only.isdigit() and len(code_only) == 6: return f"{code_only}.KS"
    elif code_only.isalnum() or '.' in code_only: return code_only.upper()
    else: return code_only

# **** ì‹ ê·œ í•¨ìˆ˜: ê¸ˆ ê°€ê²© ë°ì´í„° ë¡œë“œ ****
@st.cache_data(ttl=600)
def load_gold_price_data(_gc):
    """ğŸ“ˆê¸ˆí˜„ë¬¼ ìˆ˜ìµë¥  ì‹œíŠ¸ì—ì„œ ë‚ ì§œ(Aì—´)ì™€ ê¸ˆê°€ê²©(Jì—´)ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not isinstance(_gc, gspread.Client):
        st.error("load_gold_price_data: ìœ íš¨í•œ Google Sheets í´ë¼ì´ì–¸íŠ¸ ê°ì²´(gc)ê°€ ì•„ë‹™ë‹ˆë‹¤.")
        return pd.DataFrame()

    DATE_COL = 1  # Aì—´
    PRICE_COL = 10 # Jì—´

    try:
        print(f"Log: Loading gold price data from '{GOLD_RATE_SHEET}'...")
        spreadsheet = _gc.open(GOOGLE_SHEET_NAME)
        worksheet = spreadsheet.worksheet(GOLD_RATE_SHEET)

        # Aì—´ê³¼ Jì—´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        data = worksheet.get_all_values() # ì „ì²´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŒ
        if len(data) < 2: # í—¤ë”ë§Œ ìˆê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°
            st.warning(f"'{GOLD_RATE_SHEET}' ì‹œíŠ¸ì— ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (í—¤ë” ì œì™¸).")
            return pd.DataFrame()

        # í—¤ë”ì™€ ë°ì´í„° ë¶„ë¦¬
        header = data[0]
        records = data[1:]

        # ë°ì´í„°í”„ë ˆì„ ìƒì„± ì¤€ë¹„
        dates = []
        prices = []
        expected_date_header = 'ë‚ ì§œ' # ì‹¤ì œ ì‹œíŠ¸ì˜ A1 ì…€ ê°’
        expected_price_header = header[PRICE_COL-1] if len(header) >= PRICE_COL else f'Column_{PRICE_COL}' # J1 ì…€ ê°’ ë˜ëŠ” ê¸°ë³¸ê°’

        for i, row in enumerate(records):
            if len(row) >= PRICE_COL: # í–‰ ê¸¸ì´ê°€ ì¶©ë¶„í•œì§€ í™•ì¸
                date_str = row[DATE_COL-1]
                price_str = row[PRICE_COL-1]

                # ë‚ ì§œ íŒŒì‹±
                dt_obj = None
                try:
                    dt_obj = pd.to_datetime(date_str, errors='coerce')
                except ValueError: # ë‹¤ì–‘í•œ í˜•ì‹ ì‹œë„ (í•„ìš” ì‹œ)
                    pass

                if pd.notna(dt_obj):
                    dates.append(dt_obj)
                    # ê°€ê²© ìˆ«ì ë³€í™˜ (ì†Œìˆ˜ì  ìœ ì§€ ìœ„í•´ float)
                    prices.append(clean_numeric_value(price_str, float))
                #else: # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê²½ê³  (ë„ˆë¬´ ë§ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬)
                    #print(f"Log: Skipping row {i+2} in '{GOLD_RATE_SHEET}' due to date parsing error: '{date_str}'")

        if not dates:
            st.warning(f"'{GOLD_RATE_SHEET}' ì‹œíŠ¸ì—ì„œ ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame({'Date': dates, 'Close': prices})
        df = df.set_index('Date')
        df = df.sort_index() # ë‚ ì§œ ìˆœìœ¼ë¡œ ì •ë ¬
        print(f"Log: Gold price data loaded successfully ({len(df)} rows).")
        return df

    except gspread.exceptions.WorksheetNotFound:
        st.error(f"ì›Œí¬ì‹œíŠ¸ '{GOLD_RATE_SHEET}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"ê¸ˆ ê°€ê²© ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()
        return pd.DataFrame()
# ***************************************

# --- ë°ì´í„° ë¡œë“œ ì‹¤í–‰ ë° ëŒ€ì‹œë³´ë“œ êµ¬ì„± ---
gc = connect_google_sheets()

if gc:
    twr_data_df = load_twr_data()
    gain_loss_data = load_gain_loss_data()
    latest_balances, latest_data_date = load_latest_balances(gc)
    if latest_data_date:
        allocation_comparison_df, target_allocation_df = load_allocation_data(gc, latest_data_date)
    else:
        st.warning("ìµœì‹  ë°ì´í„° ê¸°ì¤€ì¼ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ ìì‚° ë°°ë¶„ ì •ë³´ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        allocation_comparison_df, target_allocation_df = pd.DataFrame(), pd.DataFrame()
else:
    st.error("Google Sheetsì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    twr_data_df = pd.DataFrame(); gain_loss_data = {}
    latest_balances, latest_data_date = {}, None
    allocation_comparison_df, target_allocation_df = pd.DataFrame(), pd.DataFrame()

# --- ëŒ€ì‹œë³´ë“œ ì œëª© ë° ë°ì´í„° ê¸°ì¤€ì¼ ---
st.title(PAGE_TITLE)
if latest_data_date: st.caption(f"ë°ì´í„° ê¸°ì¤€ì¼: {latest_data_date.strftime('%Yë…„ %mì›” %dì¼')}")
else: st.caption("ë°ì´í„° ê¸°ì¤€ì¼ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# --- ê°œìš” (Overview) ì„¹ì…˜ ---
st.header("ğŸ“Š ê°œìš”")
col1, col2, col3 = st.columns(3)
total_asset = 0
if latest_balances: total_asset = np.nansum(pd.to_numeric(list(latest_balances.values()), errors='coerce'))
col1.metric("ğŸ’° ì´ í‰ê°€ì•¡", f"{total_asset:,.0f} ì›")
latest_twr = "N/A"
if not twr_data_df.empty and 'Total' in twr_data_df['Account'].unique():
    total_twr_series = twr_data_df[twr_data_df['Account'] == 'Total'].sort_values(by='Date', ascending=False)
    if not total_twr_series.empty: latest_twr_value = total_twr_series['TWR'].iloc[0]; latest_twr = f"{latest_twr_value:.2f}%" if pd.notna(latest_twr_value) else "N/A"
col2.metric("ğŸ“ˆ ì „ì²´ TWR (ê¸°ê°„)", latest_twr)
total_gain_loss = "N/A"
if gain_loss_data and 'Total' in gain_loss_data and gain_loss_data['Total'] is not None: total_gain_loss = f"{gain_loss_data['Total']:,.0f} ì›"
col3.metric("ğŸ’¸ ì „ì²´ ë‹¨ìˆœ ì†ìµ (ê¸°ê°„)", total_gain_loss)
st.markdown("---")

# --- ìì‚° ë°°ë¶„ ì„¹ì…˜ ---
st.header("âš–ï¸ ìì‚° ë°°ë¶„")
if allocation_comparison_df is not None and not allocation_comparison_df.empty:
    st.subheader("í˜„ì¬ vs ëª©í‘œ ë¹„ì¤‘ ë¹„êµ")
    df_to_display = allocation_comparison_df.copy()
    total_target_amount = 0; target_amount_col_original = 'ëª©í‘œ ê¸ˆì•¡'; new_target_amount_header = target_amount_col_original
    if target_amount_col_original in df_to_display.columns:
        try: numeric_target_amounts = pd.to_numeric(df_to_display[target_amount_col_original], errors='coerce').fillna(0); total_target_amount = int(numeric_target_amounts.sum()); new_target_amount_header = f"{target_amount_col_original} (ì´ {total_target_amount:,.0f} ì›)"
        except Exception as e_sum: print(f"Warning: ëª©í‘œ ê¸ˆì•¡ ì´í•© ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e_sum}")
    formats = {'í˜„ì¬ ë¹„ì¤‘(%)': '{:.2f}%', 'ëª©í‘œ ë¹„ì¤‘(%)': '{:.2f}%', 'ì°¨ì´(%)': '{:+.2f}%', 'í˜„ì¬ í‰ê°€ì•¡': '{:,.0f} ì›', target_amount_col_original: '{:,.0f} ì›', 'í˜„ê¸ˆì°¨ì´': '{:+,d} ì›'}
    if new_target_amount_header != target_amount_col_original and target_amount_col_original in df_to_display.columns: df_to_display.rename(columns={target_amount_col_original: new_target_amount_header}, inplace=True); formats[new_target_amount_header] = formats.pop(target_amount_col_original)
    original_display_cols = ['ì¢…í•© ë¶„ë¥˜', 'ëª©í‘œ ë¹„ì¤‘(%)', 'í˜„ì¬ ë¹„ì¤‘(%)', 'ì°¨ì´(%)', 'ëª©í‘œ ê¸ˆì•¡', 'í˜„ì¬ í‰ê°€ì•¡', 'í˜„ê¸ˆì°¨ì´']
    display_cols_final = [];
    for col in original_display_cols:
        if col == target_amount_col_original and new_target_amount_header != target_amount_col_original:
             if new_target_amount_header in df_to_display.columns: display_cols_final.append(new_target_amount_header)
        elif col in df_to_display.columns: display_cols_final.append(col)
    available_formats = {k: v for k, v in formats.items() if k in display_cols_final}
    if display_cols_final:
        sort_col = 'ëª©í‘œ ë¹„ì¤‘(%)' if 'ëª©í‘œ ë¹„ì¤‘(%)' in display_cols_final else ('ì¢…í•© ë¶„ë¥˜' if 'ì¢…í•© ë¶„ë¥˜' in display_cols_final else None)
        if sort_col and sort_col == 'ëª©í‘œ ë¹„ì¤‘(%)' and not pd.api.types.is_numeric_dtype(df_to_display[sort_col]): sort_col = 'ì¢…í•© ë¶„ë¥˜'
        if sort_col: df_display_final = df_to_display[display_cols_final].sort_values(by=sort_col, ascending=False).reset_index(drop=True)
        else: df_display_final = df_to_display[display_cols_final] # ì •ë ¬ ì»¬ëŸ¼ ì—†ìœ¼ë©´ ê·¸ëƒ¥ í‘œì‹œ
        st.dataframe(df_display_final.style.format(available_formats).set_properties(**{'text-align': 'center'}))
    else: st.warning("ë¹„êµ í…Œì´ë¸” í‘œì‹œí•  ì»¬ëŸ¼ ë¶€ì¡±.")

    st.subheader("ìì‚° ë°°ë¶„ ì‹œê°í™” (ì¢…í•© ë¶„ë¥˜ ê¸°ì¤€)")
    col_chart1, col_chart2 = st.columns(2)
    with col_chart1:
        if 'í˜„ì¬ ë¹„ì¤‘(%)' in allocation_comparison_df.columns:
             current_display_df = allocation_comparison_df[allocation_comparison_df['í˜„ì¬ ë¹„ì¤‘(%)'] > 0].copy()
             if not current_display_df.empty:
                 current_display_df.sort_values(by='í˜„ì¬ ë¹„ì¤‘(%)', inplace=True); fig_current = px.pie(current_display_df, values='í˜„ì¬ ë¹„ì¤‘(%)', names='ì¢…í•© ë¶„ë¥˜', title='í˜„ì¬ ìì‚° ë°°ë¶„', hole=.4, color_discrete_sequence=px.colors.sequential.RdBu); fig_current.update_traces(textposition='outside', textinfo='percent+label', insidetextorientation='radial', sort=False); fig_current.update_layout(showlegend=False, margin=dict(l=40, r=40, t=50, b=40)); st.plotly_chart(fig_current, use_container_width=True)
             else: st.info("í˜„ì¬ ë³´ìœ  ìì‚° ë¹„ì¤‘ ì •ë³´ ì—†ìŒ (0% ì´ˆê³¼).")
        else: st.info("í˜„ì¬ ë³´ìœ  ìì‚° ë¹„ì¤‘ ì •ë³´ ì—†ìŒ.")
    with col_chart2:
        if target_allocation_df is not None and not target_allocation_df.empty and 'ëª©í‘œ ë¹„ì¤‘(%)' in target_allocation_df.columns:
             target_display_df = target_allocation_df[target_allocation_df['ëª©í‘œ ë¹„ì¤‘(%)'] > 0].copy()
             if not target_display_df.empty:
                 target_display_df.sort_values(by='ëª©í‘œ ë¹„ì¤‘(%)', inplace=True); fig_target = px.pie(target_display_df, values='ëª©í‘œ ë¹„ì¤‘(%)', names='ì¢…í•© ë¶„ë¥˜', title='ëª©í‘œ ìì‚° ë°°ë¶„', hole=.4, color_discrete_sequence=px.colors.sequential.RdBu); fig_target.update_traces(textposition='outside', textinfo='percent+label', insidetextorientation='radial', sort=False); fig_target.update_layout(showlegend=False, margin=dict(l=40, r=40, t=50, b=40)); st.plotly_chart(fig_target, use_container_width=True)
             else: st.info("ëª©í‘œ ìì‚° ë°°ë¶„ ì •ë³´ ì—†ìŒ (0% ì´ˆê³¼).")
        else: st.info("ëª©í‘œ ìì‚° ë°°ë¶„ ì •ë³´ ì—†ìŒ.")
elif allocation_comparison_df is None: st.error("ìì‚° ë°°ë¶„ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ ë˜ëŠ” ê¸°ì¤€ ë‚ ì§œ ë°ì´í„° ì—†ìŒ.")
else: st.info("í‘œì‹œí•  ìì‚° ë°°ë¶„ ì •ë³´ ì—†ìŒ.")
st.markdown("---")

# --- ì„±ê³¼ ë¶„ì„ ì„¹ì…˜ ---
st.header("ğŸ“ˆ ì„±ê³¼ ë¶„ì„")
if twr_data_df is not None and not twr_data_df.empty:
    st.subheader("ğŸ“Š ì‹œê°„ê°€ì¤‘ìˆ˜ìµë¥ (TWR) ì¶”ì´")
    st.markdown("#### ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ TWR ë° ì‹œì¥ ì§€ìˆ˜ ë¹„êµ")
    total_twr_df = twr_data_df[twr_data_df['Account'] == 'Total'].sort_values(by='Date')
    if not total_twr_df.empty:
        start_date = total_twr_df['Date'].min(); end_date = total_twr_df['Date'].max()
        kospi_raw_data = download_yf_data(KOSPI_TICKER, start_date, end_date)
        sp500_raw_data = download_yf_data(SP500_TICKER, start_date, end_date)
        kospi_twr_df = calculate_index_twr(kospi_raw_data, KOSPI_TICKER)
        sp500_twr_df = calculate_index_twr(sp500_raw_data, SP500_TICKER)
        fig_total_compare = go.Figure()
        fig_total_compare.add_trace(go.Scatter(x=total_twr_df['Date'], y=total_twr_df['TWR'], mode='lines', name='ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤', line=dict(color='royalblue', width=2.5)))
        if kospi_twr_df is not None and not kospi_twr_df.empty: fig_total_compare.add_trace(go.Scatter(x=kospi_twr_df['Date'], y=kospi_twr_df['TWR'], mode='lines', name='KOSPI 200', line=dict(color='tomato', width=1.5, dash='dash')))
        if sp500_twr_df is not None and not sp500_twr_df.empty: fig_total_compare.add_trace(go.Scatter(x=sp500_twr_df['Date'], y=sp500_twr_df['TWR'], mode='lines', name='S&P 500', line=dict(color='mediumseagreen', width=1.5, dash='dot')))
        fig_total_compare.update_layout(title='ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ TWR ë° ì‹œì¥ ì§€ìˆ˜ ë¹„êµ', xaxis_title='ë‚ ì§œ', yaxis_title='TWR (%)', legend_title='êµ¬ë¶„', hovermode="x unified")
        st.plotly_chart(fig_total_compare, use_container_width=True)
    else: st.info("ì „ì²´ TWR ë°ì´í„° ì—†ìŒ.")

    st.markdown("#### ê³„ì¢Œë³„ TWR")
    account_twr_df = twr_data_df[twr_data_df['Account'] != 'Total'].sort_values(by=['Account', 'Date'])
    if not account_twr_df.empty:
        fig_accounts_twr = px.line(account_twr_df, x='Date', y='TWR', color='Account', title='ê³„ì¢Œë³„ TWR ì¶”ì´', labels={'TWR': 'TWR (%)'})
        fig_accounts_twr.update_layout(xaxis_title='ë‚ ì§œ', yaxis_title='ìˆ˜ìµë¥  (%)')
        st.plotly_chart(fig_accounts_twr, use_container_width=True)
    else: st.info("ê°œë³„ ê³„ì¢Œ TWR ë°ì´í„° ì—†ìŒ.")

    # **** ì¢…ëª©ë³„ ê·¸ë˜í”„ ë¡œì§ ìˆ˜ì • ****
    st.markdown("---"); st.subheader("ğŸ“ˆ ì¢…ëª©ë³„ ê°€ê²©/ì£¼ê°€ ë° í‰ë‹¨ê°€ (ì´ë™í‰ê· ë²•)")
    if gc and latest_data_date:
        holdings_list_df = load_current_holdings(gc, latest_data_date)
        if holdings_list_df is not None and not holdings_list_df.empty:
            stock_options = holdings_list_df.set_index('ì¢…ëª©ëª…')['ì¢…ëª©ì½”ë“œ'].to_dict()
            stock_names = ["ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”..."] + list(holdings_list_df['ì¢…ëª©ëª…'])
            default_index = 0; default_stock_name = "TIGERë¯¸êµ­S&P500" # ê¸°ë³¸ ì„ íƒ ì¢…ëª©
            try:
                 if default_stock_name in stock_names: default_index = stock_names.index(default_stock_name)
            except ValueError: pass
            selected_stock_name = st.selectbox("ì¢…ëª© ì„ íƒ:", stock_names, index=default_index)

            if selected_stock_name != "ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”...":
                stock_code = stock_options.get(selected_stock_name)
                if stock_code:
                    avg_cost = calculate_moving_avg_cost(gc, stock_code) if gc else 0.0
                    first_purchase_dt = get_first_purchase_date(gc, stock_code) if gc else None

                    if first_purchase_dt:
                        chart_start_date = first_purchase_dt.date() # ë‚ ì§œë§Œ ì‚¬ìš©
                        current_date = datetime.now().date()
                        close_price_df = pd.DataFrame() # ì´ˆê¸°í™”
                        plot_title = f"{selected_stock_name}" # ê¸°ë³¸ ì œëª©

                        # --- ê¸ˆí˜„ë¬¼ê³¼ ë‹¤ë¥¸ ì¢…ëª© ë¡œì§ ë¶„ê¸° ---
                        if stock_code == 'GOLD':
                            st.info(f"'{selected_stock_name}' ê°€ê²© ë°ì´í„°ë¥¼ êµ¬ê¸€ ì‹œíŠ¸ '{GOLD_RATE_SHEET}'ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.")
                            gold_price_history = load_gold_price_data(gc) # ì‹ ê·œ í•¨ìˆ˜ í˜¸ì¶œ
                            if gold_price_history is not None and not gold_price_history.empty:
                                # êµ¬ë§¤ ì‹œì‘ì¼ ì´í›„ ë°ì´í„° í•„í„°ë§
                                gold_data_filtered = gold_price_history[gold_price_history.index.date >= chart_start_date]
                                if not gold_data_filtered.empty:
                                    close_price_df = gold_data_filtered # 'Close' ì»¬ëŸ¼ ì‚¬ìš©
                                    plot_title = f"{selected_stock_name} ê°€ê²© ì¶”ì´ ë° í‰ë‹¨ê°€ (KRW/g)"
                                else:
                                    st.warning(f"'{selected_stock_name}'ì˜ ë§¤ìˆ˜ ì‹œì‘ì¼({chart_start_date}) ì´í›„ ê°€ê²© ë°ì´í„°ê°€ '{GOLD_RATE_SHEET}' ì‹œíŠ¸ì— ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.warning(f"'{selected_stock_name}' ê°€ê²© ë°ì´í„°ë¥¼ '{GOLD_RATE_SHEET}' ì‹œíŠ¸ì—ì„œ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                        else: # ê¸ˆí˜„ë¬¼ ì™¸ ë‹¤ë¥¸ ì¢…ëª© (Yahoo Finance ì‚¬ìš©)
                            yf_ticker = get_yf_ticker(stock_code)
                            if not yf_ticker:
                                st.info(f"{selected_stock_name} ({stock_code})ì˜ ì™¸ë¶€ ì£¼ê°€ ì •ë³´ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                # í‰ë‹¨ê°€ë§Œ í‘œì‹œ (ê·¸ë˜í”„ ì—†ìŒ)
                                if avg_cost > 0: st.metric(label=f"{selected_stock_name} í‰ë‹¨ê°€ (ì´ë™í‰ê· )", value=f"{avg_cost:,.0f} ì›")
                                else: st.metric(label=f"{selected_stock_name} í‰ë‹¨ê°€ (ì´ë™í‰ê· )", value="ê³„ì‚° ë¶ˆê°€")
                            else:
                                st.info(f"{selected_stock_name}({yf_ticker}) ì£¼ê°€ ë°ì´í„°ë¥¼ Yahoo Financeì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.")
                                stock_price_data = download_yf_data(yf_ticker, chart_start_date, current_date)
                                if stock_price_data is not None and not stock_price_data.empty:
                                    # ì¢…ê°€ ì»¬ëŸ¼ ì°¾ê¸° (ì´ì „ ë¡œì§ ê°œì„ )
                                    close_col_found = None
                                    if isinstance(stock_price_data.columns, pd.MultiIndex):
                                        potential_cols = [('Close', yf_ticker), ('Adj Close', yf_ticker), ('Close', ''), ('Adj Close', '')]
                                        for col in potential_cols:
                                            if col in stock_price_data.columns: close_col_found = col; break
                                        if not close_col_found:
                                             level_zero = stock_price_data.columns.get_level_values(0)
                                             if 'Close' in level_zero: close_col_found = [c for c in stock_price_data.columns if c[0] == 'Close'][0]
                                             elif 'Adj Close' in level_zero: close_col_found = [c for c in stock_price_data.columns if c[0] == 'Adj Close'][0]
                                    elif 'Close' in stock_price_data.columns: close_col_found = 'Close'
                                    elif 'Adj Close' in stock_price_data.columns: close_col_found = 'Adj Close'

                                    if close_col_found:
                                        temp_df = stock_price_data[[close_col_found]].copy()
                                        temp_df.columns = ['Close'] # ì»¬ëŸ¼ëª… í†µì¼
                                        close_price_df = temp_df.dropna(subset=['Close'])
                                        plot_title = f"{selected_stock_name} ({yf_ticker}) ì£¼ê°€ ì¶”ì´ ë° í‰ë‹¨ê°€"
                                    else:
                                        st.warning(f"{selected_stock_name}({yf_ticker}) ë°ì´í„°ì—ì„œ ì¢…ê°€ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                else:
                                    st.warning(f"{selected_stock_name}({yf_ticker}) ì£¼ê°€ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        # --- ---

                        # --- ê·¸ë˜í”„ ì¶œë ¥ (ë°ì´í„°ê°€ ìˆì„ ê²½ìš° ê³µí†µ) ---
                        if not close_price_df.empty:
                            fig_stock = go.Figure()
                            fig_stock.add_trace(go.Scatter(x=close_price_df.index, y=close_price_df['Close'], mode='lines', name='ì¢…ê°€/ê°€ê²©', line=dict(color='skyblue', width=2)))

                            # í‰ë‹¨ê°€ í‘œì‹œ (avg_costê°€ 0ë³´ë‹¤ í´ ë•Œ)
                            if avg_cost > 0:
                                # ê¸ˆí˜„ë¬¼ì€ ì†Œìˆ˜ì  í‘œì‹œ, ì£¼ì‹ì€ ì •ìˆ˜ í‘œì‹œ (ì„ íƒì )
                                avg_cost_format = "{:,.2f}" if stock_code == 'GOLD' else "{:,.0f}"
                                fig_stock.add_hline(y=avg_cost, line_dash="dot", line_color="tomato",
                                                    annotation_text=f"í‰ë‹¨ê°€: {avg_cost_format.format(avg_cost)}",
                                                    annotation_position="bottom right")

                            fig_stock.update_layout(
                                title=plot_title,
                                xaxis_title='ë‚ ì§œ',
                                yaxis_title='ê°€ê²© (KRW)', # ë‹¨ìœ„ í†µì¼ (í•„ìš”ì‹œ ìˆ˜ì •)
                                yaxis=dict(showticklabels=True, autorange=True), # Yì¶• ë²”ìœ„ ìë™ ì¡°ì ˆ
                                hovermode="x unified"
                            )
                            st.plotly_chart(fig_stock, use_container_width=True)
                        elif yf_ticker: # Yahoo Finance ì‚¬ìš© ì¢…ëª©ì¸ë° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨/ì¢…ê°€ ì—†ìŒ
                             pass # ìœ„ì—ì„œ ì´ë¯¸ ê²½ê³ /ì •ë³´ ë©”ì‹œì§€ í‘œì‹œë¨
                        elif stock_code == 'GOLD' and not gold_price_history.empty: # ê¸ˆ ë°ì´í„°ëŠ” ìˆëŠ”ë° ì‹œì‘ì¼ ì´í›„ ë°ì´í„° ì—†ëŠ” ê²½ìš°
                             pass # ìœ„ì—ì„œ ì´ë¯¸ ê²½ê³  ë©”ì‹œì§€ í‘œì‹œë¨
                        elif stock_code != 'GOLD' and not yf_ticker: # ì¡°íšŒ ë¶ˆê°€ í‹°ì»¤
                             pass # ìœ„ì—ì„œ ì´ë¯¸ ì •ë³´ ë©”ì‹œì§€ í‘œì‹œë¨
                        else: # ê·¸ ì™¸ (ìµœì´ˆ ë§¤ìˆ˜ì¼ ì—†ìŒ ë“±)
                             st.info("ê·¸ë˜í”„ë¥¼ í‘œì‹œí•  ê°€ê²© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    # --- ---

                    elif gc: # first_purchase_dtê°€ ì—†ëŠ” ê²½ìš°
                         st.warning(f"{selected_stock_name}ì˜ ë§¤ìˆ˜ ê¸°ë¡ì„ '{TRADES_SHEET}' ì‹œíŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ì–´ ê·¸ë˜í”„ ì‹œì‘ì¼ì„ ì§€ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    # else: # gc ì—°ê²° ì‹¤íŒ¨ëŠ” ì´ë¯¸ ì²˜ë¦¬ë¨
                    #    pass
                else:
                    st.error("ì„ íƒëœ ì¢…ëª©ì˜ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif holdings_list_df is None:
             st.error("í˜„ì¬ ë³´ìœ  ì¤‘ì¸ ì¢…ëª© ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("í˜„ì¬ ë³´ìœ  ì¤‘ì¸ ì¢…ëª© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ('ì¼ë³„ë¹„ì¤‘_Raw' ì‹œíŠ¸ í™•ì¸ í•„ìš”)")
    else:
        st.info("êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨ ë˜ëŠ” ìµœì‹  ë°ì´í„° ë‚ ì§œê°€ ì—†ì–´ ë³´ìœ  ì¢…ëª©ì„ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    # ***************************************

elif twr_data_df is None: st.error("ì„±ê³¼ ë¶„ì„ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨.")
else: st.warning("ì„±ê³¼ ë¶„ì„ ìœ„í•œ TWR ë°ì´í„° ì—†ìŒ. `portfolio_performance.py` ì‹¤í–‰ í•„ìš”.")

st.markdown("---")

# --- ë°ì´í„° ì¡°íšŒ ì„¹ì…˜ (êµ¬í˜„ ì˜ˆì •) ---
st.header("ğŸ“ ë°ì´í„° ì¡°íšŒ (êµ¬í˜„ ì˜ˆì •)")
with st.expander("ë°ì´í„° ì¡°íšŒ ì„¹ì…˜ êµ¬í˜„ ì•„ì´ë””ì–´ ë³´ê¸°"):
    st.markdown("""
    'ë°ì´í„° ì¡°íšŒ' ì„¹ì…˜ì€ ëŒ€ì‹œë³´ë“œì˜ ë‹¤ì–‘í•œ ê³„ì‚°ê³¼ ì‹œê°í™”ì— ì‚¬ìš©ëœ **ì›ë³¸ ë°ì´í„°ë¥¼ ì‚¬ìš©ìê°€ ì§ì ‘ í™•ì¸í•˜ê³  íƒìƒ‰**í•  ìˆ˜ ìˆë„ë¡ ë§Œë“œëŠ” ê³µê°„ì…ë‹ˆë‹¤.
    êµ¬í˜„ ì•„ì´ë””ì–´:
    * **í…Œì´ë¸” í‘œì‹œ:** ì‚¬ìš©ìê°€ íŠ¹ì • ì‹œíŠ¸(ì˜ˆ: `ì¼ë³„ì”ê³ _Raw`, `ì¼ë³„ë¹„ì¤‘_Raw`, `ğŸ—“ï¸ë§¤ë§¤ì¼ì§€`, `twr_results.csv` ë“±)ë¥¼ ì„ íƒí•˜ë©´ í•´ë‹¹ ë°ì´í„°ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
    * **í•„í„°ë§/ì •ë ¬:** ë‚ ì§œ, ê³„ì¢Œëª…, ì¢…ëª©ëª… ë“±ìœ¼ë¡œ ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ê±°ë‚˜ íŠ¹ì • ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    * **ë°ì´í„° ë‹¤ìš´ë¡œë“œ:** ì‚¬ìš©ìê°€ í•„í„°ë§/ì„ íƒí•œ ë°ì´í„°ë¥¼ CSV íŒŒì¼ ë“±ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ ë°›ì„ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
    * **ê°„ë‹¨í•œ ì‹œê°í™”:** ì„ íƒëœ ë°ì´í„°ì— ëŒ€í•´ ê°„ë‹¨í•œ ë¼ì¸ ì°¨íŠ¸ë‚˜ ë§‰ëŒ€ ì°¨íŠ¸ë¥¼ ì¦‰ì„ì—ì„œ ê·¸ë ¤ë³¼ ìˆ˜ ìˆëŠ” ì˜µì…˜ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: íŠ¹ì • ì¢…ëª©ì˜ ì¼ë³„ í‰ê°€ì•¡ ì¶”ì´)
    """)
# --- ---